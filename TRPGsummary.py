import os
import re
import subprocess
import datetime
import torch
import whisper
from dotenv import load_dotenv
from bert_score import score as bert_score
from openai import OpenAI

# ==== è¨­å®š ====
load_dotenv()
api_key = os.getenv("OPENAI_API_KEY")
if not api_key:
    raise ValueError("OPENAI_API_KEY ãŒ .env ã«è¨­å®šã•ã‚Œã¦ã„ã¾ã›ã‚“ã€‚")
client = OpenAI(api_key=api_key)

# ==== å…¥åŠ› ====
print("===ã‚ã‚‰ã™ã˜é¢¨è¦ç´„æ–‡ä½œæˆ===")
title = input("ã‚·ãƒŠãƒªã‚ªã‚¿ã‚¤ãƒˆãƒ«ï¼š")
characters = input("ä¸»ãªç™»å ´äººç‰©ï¼ˆã‚«ãƒ³ãƒåŒºåˆ‡ã‚Šï¼‰ï¼š")
keywords = input("ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ï¼ãƒ¢ãƒãƒ¼ãƒ•ï¼š")
video_path = input("æ˜ åƒãƒ•ã‚¡ã‚¤ãƒ«ï¼ˆ.mp4ãƒ‘ã‚¹ï¼‰ï¼š").strip('"')

# ==== å‡ºåŠ›ãƒ•ã‚©ãƒ«ãƒ€ä½œæˆ ====
now = datetime.datetime.now().strftime("%Y%m%d_%H%M%S")
output_dir = f"output_{now}"
os.makedirs(output_dir, exist_ok=True)
cut_video_path = os.path.join(output_dir, "temp_video.mp4")
audio_path = os.path.join(output_dir, "audio.wav")

# ==== æ˜ åƒã‚’60åˆ†ã«ã‚«ãƒƒãƒˆ ====
print("â–¶ æ˜ åƒã‚’60åˆ†ã«ã‚«ãƒƒãƒˆã—ã¦ã„ã¾ã™...")
subprocess.run([
    "ffmpeg", "-y", "-i", video_path,
    "-ss", "00:00:00", "-t", "01:00:00",
    "-c", "copy", cut_video_path
], stdout=subprocess.DEVNULL, stderr=subprocess.DEVNULL)

# ==== éŸ³å£°æŠ½å‡º ====
print("â–¶ éŸ³å£°ã‚’æŠ½å‡ºã—ã¦ã„ã¾ã™...")
subprocess.run([
    "ffmpeg", "-y", "-i", cut_video_path,
    "-vn", "-acodec", "pcm_s16le", "-ar", "16000", "-ac", "1", audio_path
], stdout=subprocess.DEVNULL, stderr=subprocess.DEVNULL)

# ==== Whisperæ–‡å­—èµ·ã“ã— ====
print("ğŸ“ Whisperã§æ–‡å­—èµ·ã“ã—ä¸­...")
model = whisper.load_model("base")
transcription = model.transcribe(audio_path, fp16=False)
base_transcript = transcription["text"].strip()

with open(os.path.join(output_dir, "transcript.txt"), "w", encoding="utf-8") as f:
    f.write(base_transcript)

# ==== ã‚ã‚‰ã™ã˜æ¡ˆã®ä½œæˆ ====
print("ğŸ§  GPTã§ã‚ã‚‰ã™ã˜æ¡ˆã‚’ç”Ÿæˆä¸­...")
prompt = f"""
ã‚ãªãŸã¯ã€TRPGã®ã‚»ãƒƒã‚·ãƒ§ãƒ³ã‹ã‚‰æ˜ ç”»äºˆå‘Šé¢¨ã‚ã‚‰ã™ã˜ã‚’ä½œã‚‹ãƒ—ãƒ­ã®ãƒ©ã‚¤ã‚¿ãƒ¼ã§ã™ã€‚

ä»¥ä¸‹ã¯TRPGã‚»ãƒƒã‚·ãƒ§ãƒ³ã€Œ{title}ã€ã®å…¨æ–‡æ–‡å­—èµ·ã“ã—ã§ã™ã€‚

ä¸»ãªç™»å ´äººç‰©ï¼š{characters}
ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã‚„ãƒ¢ãƒãƒ¼ãƒ•ï¼š{keywords}

ã“ã®æ–‡å­—èµ·ã“ã—ã‚’ã‚‚ã¨ã«ã€TRPGæœªçµŒé¨“ã®äººã«ã‚‚ä¼ã‚ã‚‹ã‚ˆã†ãªã€æ„Ÿæƒ…ã«è¨´ãˆã‚‹æ˜ ç”»äºˆå‘Šã®ã‚ˆã†ãªã‚ã‚‰ã™ã˜ã‚’ã€3æ¡ˆã€‘ã€ãã‚Œãã‚Œ150ã€œ300å­—ç¨‹åº¦ã§æ›¸ã„ã¦ãã ã•ã„ã€‚
ãŸã ã—ã‚ã‚‰ã™ã˜ã‚¿ã‚¤ãƒˆãƒ«ãªã©ã¯å¿…è¦ãªãã€æœ¬æ–‡ã ã‘ã‚’å‡ºåŠ›ã—ã¦ãã ã•ã„ã€‚

--- ç™»å ´äººç‰© ---
{characters}

--- ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ãƒ»ãƒ¢ãƒãƒ¼ãƒ• ---
{keywords}

--- ã‚»ãƒƒã‚·ãƒ§ãƒ³æ–‡å­—èµ·ã“ã— ---
{base_transcript}
"""

res = client.chat.completions.create(
    model="gpt-4-1106-preview",
    messages=[{"role": "user", "content": prompt}],
    temperature=0.9
)

raw_output = res.choices[0].message.content.strip()

summary_candidates = re.split(r"\n\s*\n+", raw_output)
summary_candidates = [s.strip() for s in summary_candidates if s.strip()]

# ==== BERTScoreã«ã‚ˆã‚‹è©•ä¾¡ ====
print("ğŸ“Š BERTScoreã‚’è¨ˆç®—ä¸­...")
references = [base_transcript] * len(summary_candidates)

P, R, F1 = bert_score(summary_candidates, references, lang="ja", verbose=False)
bert_scores = F1.tolist()

# ==== BERTScoreã§æœ€è‰¯æ¡ˆé¸å®š ====
best_idx = bert_scores.index(max(bert_scores))
best_summary = summary_candidates[best_idx]

# ==== å‡ºåŠ› ====
with open(os.path.join(output_dir, "summary_candidates.txt"), "w", encoding="utf-8") as f:
    for i, s in enumerate(summary_candidates):
        f.write(f"ã€æ¡ˆ{i+1}ã€‘\n{s}\n[BERTScore(F1)]: {bert_scores[i]:.4f}\n\n")

with open(os.path.join(output_dir, "final_summary.txt"), "w", encoding="utf-8") as f:
    f.write(best_summary)

# ä¸è¦ãƒ•ã‚¡ã‚¤ãƒ«å‰Šé™¤ï¼ˆæ˜ åƒãƒ»éŸ³å£°ï¼‰
os.remove(cut_video_path)
os.remove(audio_path)

# å®Œäº†é€šçŸ¥
print("\nâœ… å…¨ãƒ—ãƒ­ã‚»ã‚¹å®Œäº†")
print(f"ğŸ“ å‡ºåŠ›ãƒ•ã‚©ãƒ«ãƒ€: {output_dir}")
print(f"ğŸ¬ æœ€è‰¯ã‚ã‚‰ã™ã˜æ¡ˆ: {os.path.join(output_dir, 'final_summary.txt')}")
